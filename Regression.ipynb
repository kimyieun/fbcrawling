{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(torch.version.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1988, 36)\n",
      "(1988, 1)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "try:\n",
    "    with open(\"./Features/Features_data/featuretest.json\", encoding='UTF8') as f:\n",
    "        features = json.load(f)\n",
    "except EnvironmentError:\n",
    "    print('No Feature File')\n",
    "\n",
    "try:\n",
    "    with open(\"./Features/Features_data/scoretest.json\", encoding='UTF8') as f:\n",
    "        scores = json.load(f)\n",
    "except EnvironmentError:\n",
    "    print(\"No Score File\")\n",
    "\n",
    "feature_num = 36\n",
    "x = np.array(features)\n",
    "print(x.shape)\n",
    "\n",
    "y = np.array(scores)\n",
    "y = np.reshape(y,(-1,1))\n",
    "#y = torch.unsqueeze(y, dim = 1)\n",
    "print(y.shape)\n",
    "kf = KFold(n_splits = 5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden1, n_hidden2, n_hidden3, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden1)   # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden1, n_hidden2)   # hidden layer\n",
    "        self.hidden3 = torch.nn.Linear(n_hidden2, n_hidden3)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden3, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.hidden2(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.hidden3(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, layer_list, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_list = torch.nn.ModuleList([])\n",
    "        for idx, value in enumerate(layer_list):\n",
    "            if idx == len(layer_list) - 1:\n",
    "                break\n",
    "            else:\n",
    "                self.hidden_list.append(torch.nn.Linear(value, layer_list[idx + 1]))\n",
    "        self.predict = torch.nn.Linear(layer_list[len(layer_list) - 1], n_output) #output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        for idx, value in enumerate(self.hidden_list):\n",
    "            x = F.relu(self.hidden_list[idx](x))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.3016, grad_fn=<AddBackward>)\n",
      "7.7249675\n",
      "tensor(0.5273, grad_fn=<AddBackward>)\n",
      "0.8488379\n",
      "tensor(0.5213, grad_fn=<AddBackward>)\n",
      "0.8597376\n",
      "tensor(0.5439, grad_fn=<AddBackward>)\n",
      "0.8190587\n",
      "tensor(0.5504, grad_fn=<AddBackward>)\n",
      "0.8074076\n",
      "tensor(0.5471, grad_fn=<AddBackward>)\n",
      "0.8133852\n",
      "tensor(0.5612, grad_fn=<AddBackward>)\n",
      "0.78799117\n",
      "tensor(0.5675, grad_fn=<AddBackward>)\n",
      "0.77664316\n",
      "tensor(0.5664, grad_fn=<AddBackward>)\n",
      "0.77868134\n",
      "tensor(0.5672, grad_fn=<AddBackward>)\n",
      "0.7771561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yieun\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(x)\n",
    "y_train = torch.from_numpy(y)\n",
    "X_train, y_train = Variable(X_train.float()), Variable(y_train.float())\n",
    "\n",
    "net = Net([feature_num, 20], 1)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "epoch = 10000\n",
    "for t in range(epoch):\n",
    "    y_train_pred = net(X_train)\n",
    "    loss = loss_func(y_train_pred, y_train)     # must be (1. nn output, 2. target)\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    y_train_bar = y_train.mean()\n",
    "    sse_train = ((y_train - y_train_pred)**2).sum()\n",
    "    sst_train = ((y_train - y_train_bar)**2).sum()\n",
    "    train_r2 = 1 - sse_train/sst_train \n",
    "    \n",
    "    if t % 1000 == 0:\n",
    "        print(train_r2)\n",
    "        print(loss.data.numpy())\n",
    "\n",
    "torch.save(net, './model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of hidden layers :  1  layer_size :  10\n",
      "hidden list :  [36, 10]\n",
      "tensor(0.5222, grad_fn=<AddBackward>) tensor(0.4956, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.7098369753157742, pvalue=3.011293304938401e-62)\n",
      "tensor(0.4769, grad_fn=<AddBackward>) tensor(0.4695, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6925227235265391, pvalue=3.962960877823901e-58)\n",
      "tensor(0.5329, grad_fn=<AddBackward>) tensor(0.4007, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6341764889086049, pvalue=3.630564241291164e-46)\n",
      "tensor(0.5245, grad_fn=<AddBackward>) tensor(0.4728, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6953771328814413, pvalue=1.2110944802914797e-58)\n",
      "tensor(0.5426, grad_fn=<AddBackward>) tensor(0.3238, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6009033447014754, pvalue=2.498500109647576e-40)\n",
      "Net(\n",
      "  (hidden_list): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=10, bias=True)\n",
      "  )\n",
      "  (predict): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "average_rho : 0.666563333066767 average_pvalue : 4.997007480423634e-41\n",
      "average_r_squared_train : tensor(0.5198, grad_fn=<DivBackward0>) average_r_squared_test : tensor(0.4325, grad_fn=<DivBackward0>)\n",
      "\n",
      "the number of hidden layers :  1  layer_size :  20\n",
      "hidden list :  [36, 20]\n",
      "tensor(0.5717, grad_fn=<AddBackward>) tensor(0.3798, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6285422339531774, pvalue=3.8115831096861554e-45)\n",
      "tensor(0.5650, grad_fn=<AddBackward>) tensor(0.4685, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6896421006081608, pvalue=1.7996569265568453e-57)\n",
      "tensor(0.5765, grad_fn=<AddBackward>) tensor(0.4700, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6865517775269193, pvalue=8.947395779928544e-57)\n",
      "tensor(0.5624, grad_fn=<AddBackward>) tensor(0.4646, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6869354703843887, pvalue=1.0112788716077621e-56)\n",
      "tensor(0.5371, grad_fn=<AddBackward>) tensor(0.4570, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6832301735093775, pvalue=6.726722011915771e-56)\n",
      "Net(\n",
      "  (hidden_list): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=20, bias=True)\n",
      "  )\n",
      "  (predict): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n",
      "average_rho : 0.6749803511964048 average_pvalue : 7.623166219548566e-46\n",
      "average_r_squared_train : tensor(0.5625, grad_fn=<DivBackward0>) average_r_squared_test : tensor(0.4480, grad_fn=<DivBackward0>)\n",
      "\n",
      "the number of hidden layers :  1  layer_size :  30\n",
      "hidden list :  [36, 30]\n",
      "tensor(0.5720, grad_fn=<AddBackward>) tensor(0.4061, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6481637475257281, pvalue=8.533888737877777e-49)\n",
      "tensor(0.6043, grad_fn=<AddBackward>) tensor(0.3632, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6400711260442215, pvalue=2.942707239263793e-47)\n",
      "tensor(0.5924, grad_fn=<AddBackward>) tensor(0.5008, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.7068046958107305, pvalue=1.6669353816390392e-61)\n",
      "tensor(0.5992, grad_fn=<AddBackward>) tensor(0.4174, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6584591225027304, pvalue=1.0716273615986953e-50)\n",
      "tensor(0.5728, grad_fn=<AddBackward>) tensor(0.4775, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6990313451932569, pvalue=1.7000341306912892e-59)\n",
      "Net(\n",
      "  (hidden_list): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=30, bias=True)\n",
      "  )\n",
      "  (predict): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "average_rho : 0.6705060074153335 average_pvalue : 6.058235508011773e-48\n",
      "average_r_squared_train : tensor(0.5882, grad_fn=<DivBackward0>) average_r_squared_test : tensor(0.4330, grad_fn=<DivBackward0>)\n",
      "\n",
      "the number of hidden layers :  1  layer_size :  40\n",
      "hidden list :  [36, 40]\n",
      "tensor(0.6015, grad_fn=<AddBackward>) tensor(0.4077, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6564176006993423, pvalue=2.0604209809050571e-50)\n",
      "tensor(0.6036, grad_fn=<AddBackward>) tensor(0.4816, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.7022719677864591, pvalue=2.0665040809733118e-60)\n",
      "tensor(0.6032, grad_fn=<AddBackward>) tensor(0.3544, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6279433543909021, pvalue=4.879910360735236e-45)\n",
      "tensor(0.5895, grad_fn=<AddBackward>) tensor(0.3969, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.639615405777295, pvalue=4.66393790752999e-47)\n",
      "tensor(0.6091, grad_fn=<AddBackward>) tensor(0.4680, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6915038865274836, pvalue=9.399807067739564e-58)\n",
      "Net(\n",
      "  (hidden_list): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=40, bias=True)\n",
      "  )\n",
      "  (predict): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n",
      "average_rho : 0.6635504430362964 average_pvalue : 9.853140688042574e-46\n",
      "average_r_squared_train : tensor(0.6014, grad_fn=<DivBackward0>) average_r_squared_test : tensor(0.4217, grad_fn=<DivBackward0>)\n",
      "\n",
      "the number of hidden layers :  2  layer_size :  10\n",
      "hidden list :  [36, 10, 10]\n",
      "tensor(0.5726, grad_fn=<AddBackward>) tensor(0.4188, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6625483654883028, pvalue=1.2006330163920926e-51)\n",
      "tensor(0.5738, grad_fn=<AddBackward>) tensor(0.4703, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.691385270190873, pvalue=7.218303951553161e-58)\n",
      "tensor(0.5720, grad_fn=<AddBackward>) tensor(0.4418, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6727990797737294, pvalue=8.887224536222272e-54)\n",
      "tensor(0.5300, grad_fn=<AddBackward>) tensor(0.5266, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.7297043888886444, pvalue=3.364445079238283e-67)\n",
      "tensor(0.5416, grad_fn=<AddBackward>) tensor(0.3240, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.5944740258374258, pvalue=2.6784859024554792e-39)\n",
      "Net(\n",
      "  (hidden_list): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=10, bias=True)\n",
      "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      "  (predict): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "average_rho : 0.6701822260357951 average_pvalue : 5.356971804913377e-40\n",
      "average_r_squared_train : tensor(0.5580, grad_fn=<DivBackward0>) average_r_squared_test : tensor(0.4363, grad_fn=<DivBackward0>)\n",
      "\n",
      "the number of hidden layers :  2  layer_size :  20\n",
      "hidden list :  [36, 20, 20]\n",
      "tensor(0.6037, grad_fn=<AddBackward>) tensor(0.4275, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6726293100502749, pvalue=9.65499366656757e-54)\n",
      "tensor(0.6552, grad_fn=<AddBackward>) tensor(0.3818, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.654856150681558, pvalue=4.205208390678752e-50)\n",
      "tensor(0.6509, grad_fn=<AddBackward>) tensor(0.3257, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6090324597336884, pvalue=9.120882472729537e-42)\n",
      "tensor(0.6530, grad_fn=<AddBackward>) tensor(0.3063, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6078096367217696, pvalue=1.839634951621952e-41)\n",
      "tensor(0.6224, grad_fn=<AddBackward>) tensor(0.3941, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6519269982700148, pvalue=2.0930759346870967e-49)\n",
      "Net(\n",
      "  (hidden_list): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=20, bias=True)\n",
      "    (1): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  (predict): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n",
      "average_rho : 0.6392509110914611 average_pvalue : 5.503446448063677e-42\n",
      "average_r_squared_train : tensor(0.6370, grad_fn=<DivBackward0>) average_r_squared_test : tensor(0.3671, grad_fn=<DivBackward0>)\n",
      "\n",
      "the number of hidden layers :  2  layer_size :  30\n",
      "hidden list :  [36, 30, 30]\n",
      "tensor(0.6677, grad_fn=<AddBackward>) tensor(0.4389, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6734155223039393, pvalue=6.57502934990241e-54)\n",
      "tensor(0.6861, grad_fn=<AddBackward>) tensor(0.3479, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6249049351838818, pvalue=1.6952762104890436e-44)\n",
      "tensor(0.6470, grad_fn=<AddBackward>) tensor(0.4328, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6748490688990915, pvalue=3.253349339464582e-54)\n",
      "tensor(0.6814, grad_fn=<AddBackward>) tensor(0.3827, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6509395151028735, pvalue=3.2594255362081476e-49)\n",
      "tensor(0.6850, grad_fn=<AddBackward>) tensor(0.3982, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6428538555500155, pvalue=1.1523437356057088e-47)\n",
      "Net(\n",
      "  (hidden_list): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=30, bias=True)\n",
      "    (1): Linear(in_features=30, out_features=30, bias=True)\n",
      "  )\n",
      "  (predict): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "average_rho : 0.6533925794079603 average_pvalue : 3.3929222989256984e-45\n",
      "average_r_squared_train : tensor(0.6735, grad_fn=<DivBackward0>) average_r_squared_test : tensor(0.4001, grad_fn=<DivBackward0>)\n",
      "\n",
      "the number of hidden layers :  2  layer_size :  40\n",
      "hidden list :  [36, 40, 40]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6915, grad_fn=<AddBackward>) tensor(0.3598, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6370791569951617, pvalue=1.0607102368145199e-46)\n",
      "tensor(0.6792, grad_fn=<AddBackward>) tensor(0.3824, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6498037303181136, pvalue=4.109863031810027e-49)\n",
      "tensor(0.7121, grad_fn=<AddBackward>) tensor(0.3622, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6559350945536498, pvalue=2.569770122036786e-50)\n",
      "tensor(0.6916, grad_fn=<AddBackward>) tensor(0.3350, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6268777695572505, pvalue=9.720862999853885e-45)\n",
      "tensor(0.7060, grad_fn=<AddBackward>) tensor(0.2159, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.5443578776752862, pvalue=5.258418502103776e-32)\n",
      "Net(\n",
      "  (hidden_list): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=40, bias=True)\n",
      "    (1): Linear(in_features=40, out_features=40, bias=True)\n",
      "  )\n",
      "  (predict): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n",
      "average_rho : 0.6228107258198923 average_pvalue : 1.0516837004209518e-32\n",
      "average_r_squared_train : tensor(0.6961, grad_fn=<DivBackward0>) average_r_squared_test : tensor(0.3310, grad_fn=<DivBackward0>)\n",
      "\n",
      "the number of hidden layers :  3  layer_size :  10\n",
      "hidden list :  [36, 10, 10, 10]\n",
      "tensor(0.5799, grad_fn=<AddBackward>) tensor(0.4265, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6646276383125356, pvalue=4.508757170732253e-52)\n",
      "tensor(0.5693, grad_fn=<AddBackward>) tensor(0.3552, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6100589255150258, pvalue=6.138951462800047e-42)\n",
      "tensor(0.5585, grad_fn=<AddBackward>) tensor(0.4012, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6463781569610452, pvalue=1.8811460091455724e-48)\n",
      "tensor(0.5698, grad_fn=<AddBackward>) tensor(0.4759, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6913926844188233, pvalue=9.96464150868396e-58)\n",
      "tensor(0.5998, grad_fn=<AddBackward>) tensor(0.4604, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6857390322204423, pvalue=1.8704204181678564e-56)\n",
      "Net(\n",
      "  (hidden_list): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=10, bias=True)\n",
      "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      "  (predict): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "average_rho : 0.6596392874855744 average_pvalue : 1.2277906688793904e-42\n",
      "average_r_squared_train : tensor(0.5755, grad_fn=<DivBackward0>) average_r_squared_test : tensor(0.4238, grad_fn=<DivBackward0>)\n",
      "\n",
      "the number of hidden layers :  3  layer_size :  20\n",
      "hidden list :  [36, 20, 20, 20]\n",
      "tensor(0.6818, grad_fn=<AddBackward>) tensor(0.2934, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.603662474035373, pvalue=7.069961153411277e-41)\n",
      "tensor(0.6756, grad_fn=<AddBackward>) tensor(0.3634, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6347812179397204, pvalue=2.812647153236396e-46)\n",
      "tensor(0.6662, grad_fn=<AddBackward>) tensor(0.3689, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.642835824662426, pvalue=8.885245546137333e-48)\n",
      "tensor(0.6528, grad_fn=<AddBackward>) tensor(0.3856, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6534466461450262, pvalue=1.0552569856544376e-49)\n",
      "tensor(0.6502, grad_fn=<AddBackward>) tensor(0.3990, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6541090564733455, pvalue=7.819400570845053e-50)\n",
      "Net(\n",
      "  (hidden_list): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=20, bias=True)\n",
      "    (1): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  (predict): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n",
      "average_rho : 0.6377670438511782 average_pvalue : 1.4139980373558668e-41\n",
      "average_r_squared_train : tensor(0.6653, grad_fn=<DivBackward0>) average_r_squared_test : tensor(0.3621, grad_fn=<DivBackward0>)\n",
      "\n",
      "the number of hidden layers :  3  layer_size :  30\n",
      "hidden list :  [36, 30, 30, 30]\n",
      "tensor(0.7069, grad_fn=<AddBackward>) tensor(0.3001, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6120254164139404, pvalue=2.8636985383893114e-42)\n",
      "tensor(0.6519, grad_fn=<AddBackward>) tensor(0.3483, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6231431933862411, pvalue=3.468178302479661e-44)\n",
      "tensor(0.7037, grad_fn=<AddBackward>) tensor(0.3768, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6332719176350363, pvalue=5.313007040575229e-46)\n",
      "tensor(0.6354, grad_fn=<AddBackward>) tensor(0.4900, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.7162533307695955, pvalue=1.07379239658334e-63)\n",
      "tensor(0.7273, grad_fn=<AddBackward>) tensor(0.2883, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.5855134938394533, pvalue=6.693052890785441e-38)\n",
      "Net(\n",
      "  (hidden_list): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=30, bias=True)\n",
      "    (1): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (2): Linear(in_features=30, out_features=30, bias=True)\n",
      "  )\n",
      "  (predict): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "average_rho : 0.6340414704088534 average_pvalue : 1.3386685563895304e-38\n",
      "average_r_squared_train : tensor(0.6850, grad_fn=<DivBackward0>) average_r_squared_test : tensor(0.3607, grad_fn=<DivBackward0>)\n",
      "\n",
      "the number of hidden layers :  3  layer_size :  40\n",
      "hidden list :  [36, 40, 40, 40]\n",
      "tensor(0.7504, grad_fn=<AddBackward>) tensor(0.2666, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.5930066131556133, pvalue=3.674057785430628e-39)\n",
      "tensor(0.6949, grad_fn=<AddBackward>) tensor(0.3087, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6294132588361655, pvalue=2.6583801162997843e-45)\n",
      "tensor(0.7312, grad_fn=<AddBackward>) tensor(0.3920, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.6594454246974716, pvalue=5.1035455526784874e-51)\n",
      "tensor(0.6222, grad_fn=<AddBackward>) tensor(0.2425, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.5566219469918972, pvalue=1.120669217357317e-33)\n",
      "tensor(0.7476, grad_fn=<AddBackward>) tensor(0.1754, grad_fn=<AddBackward>)\n",
      "SpearmanrResult(correlation=0.5551149914971211, pvalue=1.8138084286026058e-33)\n",
      "Net(\n",
      "  (hidden_list): ModuleList(\n",
      "    (0): Linear(in_features=36, out_features=40, bias=True)\n",
      "    (1): Linear(in_features=40, out_features=40, bias=True)\n",
      "    (2): Linear(in_features=40, out_features=40, bias=True)\n",
      "  )\n",
      "  (predict): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n",
      "average_rho : 0.5987204470356537 average_pvalue : 5.868962640040733e-34\n",
      "average_r_squared_train : tensor(0.7093, grad_fn=<DivBackward0>) average_r_squared_test : tensor(0.2770, grad_fn=<DivBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max = 0       \n",
    "epoch = 10000\n",
    "\n",
    "for layer_num in range(1, 4):\n",
    "    for layer_size in [10, 20, 30, 40]:\n",
    "        sum_rho = 0\n",
    "        sum_pvalue = 0\n",
    "        sum_rsquare_train = 0\n",
    "        sum_rsquare_test = 0\n",
    "        hidden_list = [feature_num]\n",
    "        print(\"the number of hidden layers : \", layer_num, \" layer_size : \", layer_size)\n",
    "        for i in range(layer_num):\n",
    "            hidden_list.append(layer_size)\n",
    "        print(\"hidden list : \", hidden_list)\n",
    "        for train_index, test_index in kf.split(x):\n",
    "            X_train, X_test = x[train_index], x[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            X_train = torch.from_numpy(X_train)\n",
    "            X_test = torch.from_numpy(X_test)\n",
    "            y_train = torch.from_numpy(y_train)\n",
    "            y_test = torch.from_numpy(y_test)\n",
    "\n",
    "            X_train, y_train = Variable(X_train.float()), Variable(y_train.float())\n",
    "            X_test, y_test = Variable(X_test.float()), Variable(y_test.float())\n",
    "\n",
    "            net = Net(hidden_list, 1)\n",
    "            #net = Net(n_feature=feature_num, n_hidden1 = 50, n_hidden2 = 50, n_hidden3 = 50, n_output=1)     # define the network\n",
    "            # print(net, net.hidden_list)  # net architecture\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "            loss_func = torch.nn.MSELoss()\n",
    "\n",
    "            for t in range(epoch):\n",
    "                y_train_pred = net(X_train)     # input x and predict based on x\n",
    "\n",
    "                loss = loss_func(y_train_pred, y_train)     # must be (1. nn output, 2. target)\n",
    "                optimizer.zero_grad()   # clear gradients for next train\n",
    "                loss.backward()         # backpropagation, compute gradients\n",
    "                optimizer.step()        # apply gradients\n",
    "\n",
    "                y_test_pred = net(X_test)\n",
    "                y_test_pred = torch.clamp(y_test_pred, min=1, max=5)\n",
    "\n",
    "                y_train_bar = y_train.mean()\n",
    "                sse_train = ((y_train - y_train_pred)**2).sum()\n",
    "                sst_train = ((y_train - y_train_bar)**2).sum()\n",
    "\n",
    "                y_test_bar = y_test.mean()\n",
    "                sse_test = ((y_test - y_test_pred)**2).sum()\n",
    "                sst_test = ((y_test - y_test_bar)**2).sum()\n",
    "\n",
    "                train_r2 = 1 - sse_train/sst_train \n",
    "                test_r2 = 1 - sse_test/sst_test\n",
    "\n",
    "                #if t % 1000 == 0:\n",
    "                    #print('loss', loss)\n",
    "\n",
    "                if t == epoch - 1:\n",
    "                    #print(train_r2, test_r2)\n",
    "                    #print(loss.data.numpy())\n",
    "                    print(train_r2, test_r2)\n",
    "                    sum_rsquare_train += train_r2\n",
    "                    sum_rsquare_test += test_r2\n",
    "                    print(spearmanr(y_test.detach().numpy(), y_test_pred.detach().numpy()))\n",
    "                    sum_rho += spearmanr(y_test.detach().numpy(), y_test_pred.detach().numpy()).correlation\n",
    "                    sum_pvalue += spearmanr(y_test.detach().numpy(), y_test_pred.detach().numpy()).pvalue\n",
    "                    # print(y_test, y_test_pred)\n",
    "                    '''\n",
    "                    #draw excel validation answer - prediction scatterplot\n",
    "                    y_test_np = y_test.data.numpy()\n",
    "                    y_test_pred_np = y_test_pred.data.numpy()\n",
    "                    np.savetxt(str(filenum) + \"positive_test.csv\", y_test_np, delimiter=\",\")\n",
    "                    np.savetxt(str(filenum) + \"positive_test_pred.csv\", y_test_pred_np, delimiter=\",\")\n",
    "                    filenum += 1\n",
    "                    '''\n",
    "\n",
    "                    #np.savetxt(str(filenum) + \"train.txt\", y_train.data.numpy() + y_train_pred.data.numpy())\n",
    "                    #filenum += 1\n",
    "                    #print(y_test, y_test_pred)\n",
    "            #np.savetxt(str(foldnum) + \"test.csv\", ans, delimiter=\",\")\n",
    "            #np.savetxt(str(foldnum) + \"test_pred.csv\",pred, delimiter=\",\")\n",
    "            #foldnum += 1\n",
    "        print(net)\n",
    "        print(\"average_rho : \" + str(sum_rho / kf.n_splits) + \" average_pvalue : \" + str(sum_pvalue / kf.n_splits))\n",
    "        print(\"average_r_squared_train : \" + str(sum_rsquare_train / kf.n_splits) + \" average_r_squared_test : \" + str(sum_rsquare_test / kf.n_splits))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
